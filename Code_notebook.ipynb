{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "project.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.7"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "E6ExRbK7_eSR",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "import os\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.ticker as ticker\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "import plotly.graph_objects as go\n",
        "import unicodedata\n",
        "import re\n",
        "import numpy as np\n",
        "import io\n",
        "import time\n",
        "import jieba"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "k_qRmMLDIp3Y",
        "outputId": "9d3ca0fb-6d82-45c0-e3ff-e901e671b619",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "5VUuduh3XEqb"
      },
      "source": [
        "## Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "b4iEowzU_bgB",
        "colab": {}
      },
      "source": [
        "# Converts the unicode file to ascii\n",
        "def unicode_to_ascii(s):\n",
        "    return ''.join(c for c in unicodedata.normalize('NFD', s)\n",
        "        if unicodedata.category(c) != 'Mn')\n",
        "\n",
        "# cut chinese\n",
        "def cutword(sentence):\n",
        "    output = []\n",
        "    for word in jieba.cut(sentence, cut_all=False):\n",
        "        output.append(word)\n",
        "    output = ' '.join(output)\n",
        "    return output\n",
        "\n",
        "def preprocess_sentence(w):\n",
        "    w = unicode_to_ascii(w.lower().strip())\n",
        "\n",
        "    # creating a space between a word and the punctuation following it\n",
        "    w = re.sub(r\"([?.!,？。！，])\", r\" \\1 \", w)\n",
        "    # delete extra spaces\n",
        "    w = re.sub(r'[\" \"]+', \" \", w)\n",
        "\n",
        "    # replacing everything with space except (a-z, A-Z, \".\", \"?\", \"!\", \",\")\n",
        "    # as well as Chinese characters\n",
        "    w = re.sub(r\"[^a-zA-Z?.!,？。！，\\u4e00-\\u9FFF]+\", \" \", w)\n",
        "\n",
        "    # cut words\n",
        "    if len(re.findall('([a-z])',w)) == 0:\n",
        "        try:\n",
        "            w = cutword(w)\n",
        "        except:\n",
        "            pass\n",
        "\n",
        "    # adding a start and an end token to the sentence\n",
        "    # so that the model know when to start and stop predicting.\n",
        "    w = '<start> ' + w + ' <end>'\n",
        "    return w\n",
        "\n",
        "# Return word pairs in the format: [ENGLISH, CHINESE]\n",
        "def create_dataset(path, num_examples):\n",
        "    lines = io.open(path, encoding='UTF-8').read().strip().split('\\n')\n",
        "    word_pairs = []\n",
        "    for line in lines[:num_examples]:\n",
        "        sentences = line.split('\\t')[:2]\n",
        "        word_pairs.append((preprocess_sentence(sentences[0]),\n",
        "                           preprocess_sentence(sentences[1])))\n",
        "    return word_pairs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "JGtKeQTTHYbL",
        "outputId": "7ef871b9-1424-4308-f7f2-8ff2374e2c56",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "cutword(\"我可以借这本书吗？\" )"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Building prefix dict from the default dictionary ...\n",
            "Loading model from cache /tmp/jieba.cache\n",
            "Loading model cost 0.599 seconds.\n",
            "Prefix dict has been built successfully.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'我 可以 借 这 本书 吗 ？'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "qGWslS62_8Kw",
        "outputId": "22801846-3d51-4378-f2d7-07eebc4de496",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "en_sentence = u\"May I borrow this book?\"\n",
        "zh_sentence = u\"我可以借这本书吗？\"\n",
        "print(preprocess_sentence(en_sentence))\n",
        "print(preprocess_sentence(zh_sentence))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<start> may i borrow this book ?  <end>\n",
            "<start> 我 可以 借 这 本书 吗   ？   <end>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "RoAvK_hYN_gE",
        "outputId": "da90c8b3-e30d-44a4-abfb-46c54454b792",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 697
        }
      },
      "source": [
        "path_to_file = '/content/drive/My Drive/cmn.txt'\n",
        "\n",
        "for l,k in create_dataset(path_to_file, 10):\n",
        "    print(l)\n",
        "    print(k)\n",
        "    print('English length: {}; Chinese length: {}'.format(len(l),len(k)))\n",
        "    print('--' *30)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<start> hi .  <end>\n",
            "<start> 嗨   。   <end>\n",
            "English length: 19; Chinese length: 21\n",
            "------------------------------------------------------------\n",
            "<start> hi .  <end>\n",
            "<start> 你好   。   <end>\n",
            "English length: 19; Chinese length: 22\n",
            "------------------------------------------------------------\n",
            "<start> run .  <end>\n",
            "<start> 你 用 跑 的   。   <end>\n",
            "English length: 20; Chinese length: 27\n",
            "------------------------------------------------------------\n",
            "<start> wait !  <end>\n",
            "<start> 等等   ！   <end>\n",
            "English length: 21; Chinese length: 22\n",
            "------------------------------------------------------------\n",
            "<start> wait !  <end>\n",
            "<start> 等 一下   ！   <end>\n",
            "English length: 21; Chinese length: 24\n",
            "------------------------------------------------------------\n",
            "<start> hello !  <end>\n",
            "<start> 你好   。   <end>\n",
            "English length: 22; Chinese length: 22\n",
            "------------------------------------------------------------\n",
            "<start> i try .  <end>\n",
            "<start> 让 我 来   。   <end>\n",
            "English length: 22; Chinese length: 25\n",
            "------------------------------------------------------------\n",
            "<start> i won !  <end>\n",
            "<start> 我 赢 了   。   <end>\n",
            "English length: 22; Chinese length: 25\n",
            "------------------------------------------------------------\n",
            "<start> oh no !  <end>\n",
            "<start> 不会 吧   。   <end>\n",
            "English length: 22; Chinese length: 24\n",
            "------------------------------------------------------------\n",
            "<start> cheers !  <end>\n",
            "<start> 乾杯   !   <end>\n",
            "English length: 23; Chinese length: 22\n",
            "------------------------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Sbba_wsSH1vY",
        "outputId": "cfd8f5ce-a07a-4f46-8a72-d47e77582c93",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        }
      },
      "source": [
        "english = []\n",
        "chinese = []\n",
        "\n",
        "for en, zh in create_dataset(path_to_file, None):\n",
        "    english.append(en)\n",
        "    chinese.append(zh)\n",
        "\n",
        "print('--------- Original ---------')\n",
        "with open (path_to_file) as f:\n",
        "    for i in (f.read().split('\\n')[-2].split('\\t')):\n",
        "        print(i)\n",
        "print('')\n",
        "print('--------- Processed ---------')\n",
        "print(english[-1])\n",
        "print(chinese[-1])\n",
        "print('')\n",
        "print('Number of English Sentences: ', len(english))\n",
        "print('Number of Chinese sentences: ', len(chinese))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--------- Original ---------\n",
            "If a person has not had a chance to acquire his target language by the time he's an adult, he's unlikely to be able to reach native speaker level in that language.\n",
            "如果一個人在成人前沒有機會習得目標語言，他對該語言的認識達到母語者程度的機會是相當小的。\n",
            "CC-BY 2.0 (France) Attribution: tatoeba.org #1230633 (alec) & #1205914 (cienias)\n",
            "\n",
            "--------- Processed ---------\n",
            "<start> if a person has not had a chance to acquire his target language by the time he s an adult , he s unlikely to be able to reach native speaker level in that language .  <end>\n",
            "<start> 如果 一個 人 在 成人 前 沒 有 機會習 得 目標 語言   ，   他 對 該 語言 的 認識 達 到 母語者 程度 的 機會 是 相當 小 的   。   <end>\n",
            "\n",
            "Number of English Sentences:  22075\n",
            "Number of Chinese sentences:  22075\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "_IKMbepnRR03"
      },
      "source": [
        "## Tokenization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "FaMp-MlPzW5E",
        "colab": {}
      },
      "source": [
        "# create a helper function to get the padded tensor length\n",
        "# the default level(0.98) means that 98% of all sentences have fewer than n tokens\n",
        "def get_pad_len(tensor, level=0.98): \n",
        "    n = 0\n",
        "    while True:\n",
        "        count = 0\n",
        "        for i in tensor:\n",
        "            if len(i) < n:\n",
        "                count += 1\n",
        "        if count / len(tensor) >= level:\n",
        "            break\n",
        "        n += 1\n",
        "    return n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "NHgSIKmEsWa1",
        "colab": {}
      },
      "source": [
        "def to_tensor(lang, return_tensor=True, return_tokenizer=False):\n",
        "    # Assigns the index (sequence) of each word in a text to X\n",
        "    tokenizer = Tokenizer(filters=' ', oov_token='<OOV>') \n",
        "    tokenizer.fit_on_texts(lang)\n",
        "    lang_tensor = tokenizer.texts_to_sequences(lang)\n",
        "    lang_tensor = pad_sequences(lang_tensor,\n",
        "                                maxlen=get_pad_len(lang_tensor), # use the previously created function\n",
        "                                padding='post',\n",
        "                                truncating='post') \n",
        "    if return_tensor:\n",
        "        print('\\nShape of data tensor:', lang_tensor.shape)\n",
        "        return lang_tensor\n",
        "    if return_tokenizer:\n",
        "        return tokenizer"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "MclwySvSyzTC",
        "outputId": "9c739272-141f-48b6-d987-33fa2ceab6b2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        }
      },
      "source": [
        "english_tokenizer = to_tensor(english, False, True)\n",
        "english_tensor = to_tensor(english)\n",
        "print('\\nOriginal sentence:')\n",
        "print(english[500])\n",
        "print('\\nTensor of the sentence:')\n",
        "print(english_tensor[500])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Shape of data tensor: (22075, 17)\n",
            "\n",
            "Original sentence:\n",
            "<start> i m all ears .  <end>\n",
            "\n",
            "Tensor of the sentence:\n",
            "[   2    5   40   57 1360    4    3    0    0    0    0    0    0    0\n",
            "    0    0    0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "W72oQWSzwQBo",
        "outputId": "5219cdf4-04c0-49ec-f6c2-667eab7cdb50",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        }
      },
      "source": [
        "chinese_tokenizer = to_tensor(chinese, False, True)\n",
        "chinese_tensor = to_tensor(chinese)\n",
        "print('\\nOriginal sentence:')\n",
        "print(chinese[500])\n",
        "print('\\nTensor of the sentence:')\n",
        "print(chinese_tensor[500])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Shape of data tensor: (22075, 15)\n",
            "\n",
            "Original sentence:\n",
            "<start> 我 洗耳 恭聽   。   <end>\n",
            "\n",
            "Tensor of the sentence:\n",
            "[   2    5 6207 6208    4    3    0    0    0    0    0    0    0    0\n",
            "    0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "SDUy9FeTSM3T",
        "outputId": "48dad413-281e-43f7-ab3f-f5bb62ebce7e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "english_vocab_size = len(english_tokenizer.word_index) + 1\n",
        "chinese_vocab_size = len(chinese_tokenizer.word_index) + 1\n",
        "\n",
        "print('Found {} unique tokens in English.\\n'.format(english_vocab_size))\n",
        "print('Found {} unique tokens in Chinese.\\n'.format(chinese_vocab_size))\n",
        "\n",
        "name_dict = ['Chinese', 'English']\n",
        "for idx, lang in enumerate([chinese_tokenizer, english_tokenizer]):\n",
        "    print('The 10 most frequent tokens in {} are:'.format(name_dict[idx]))\n",
        "    for idx, word in enumerate(lang.word_index):\n",
        "        if word not in ['<OOV>' , '<start>', '<end>']:\n",
        "            print(word, end='|')\n",
        "        if idx == 13:\n",
        "            break\n",
        "    print('\\n')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 6237 unique tokens in English.\n",
            "\n",
            "Found 14052 unique tokens in Chinese.\n",
            "\n",
            "The 10 most frequent tokens in Chinese are:\n",
            "。|我|的|了|你|他|？|在|是|她|，|\n",
            "\n",
            "The 10 most frequent tokens in English are:\n",
            ".|i|the|to|you|a|?|is|he|t|tom|\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ZW8pt8Y3XJ1M"
      },
      "source": [
        "## Create Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "lmO2tDaV6bJh",
        "colab": {}
      },
      "source": [
        "english_train, english_test, chinese_train, chinese_test = train_test_split(\n",
        "    english_tensor, chinese_tensor, test_size=0.1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Wjo5Fr7Nb7_f",
        "colab": {}
      },
      "source": [
        "BUFFER_SIZE = len(english_train)\n",
        "BATCH_SIZE = 64\n",
        "STEPS_PER_EPOCH = len(english_train)//BATCH_SIZE\n",
        "EMBEDDING_DIM = 128\n",
        "ENC_HIDDEN_DIM = 1024\n",
        "DEC_HIDDEN_DIM = 1024\n",
        "\n",
        "# creating a TensorFlow Dataset object \n",
        "dataset = tf.data.Dataset.from_tensor_slices((english_train, chinese_train)).shuffle(BUFFER_SIZE)\n",
        "\n",
        "# batching\n",
        "dataset = dataset.batch(BATCH_SIZE, drop_remainder=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "XZks3V5Ngp_6",
        "outputId": "6c30c8cb-aacc-4844-9234-8b33889390f2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "print(chinese_vocab_size)\n",
        "print(english_vocab_size)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "14052\n",
            "6237\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "SZgryyDVwZfQ"
      },
      "source": [
        "## Encoder-decoder with attention"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "a4xrvVK_258X",
        "colab": {}
      },
      "source": [
        "class Encoder(tf.keras.Model):\n",
        "    def __init__(self, input_dim, embedding_dim, enc_hidden_dim, batch_size, dropout_rate=0.1):\n",
        "        super(Encoder, self).__init__()\n",
        "        self.batch_size = batch_size\n",
        "        self.enc_hidden_dim = enc_hidden_dim\n",
        "        # embed the word vectors\n",
        "        self.embedding = tf.keras.layers.Embedding(input_dim, embedding_dim)\n",
        "        # dropout layer for normalization\n",
        "        self.dropout = tf.keras.layers.Dropout(dropout_rate)\n",
        "        # GRU \n",
        "        self.gru = tf.keras.layers.GRU(self.enc_hidden_dim,\n",
        "                                       return_sequences=True,\n",
        "                                       return_state=True,\n",
        "                                       recurrent_initializer='glorot_uniform')\n",
        "\n",
        "    def call(self, x, init_state, training=True):\n",
        "        \"\"\"\n",
        "        training -> bool\n",
        "        \"\"\"\n",
        "        x = self.embedding(x)\n",
        "        x = self.dropout(x)\n",
        "        output, hidden = self.gru(x, initial_state = init_state, training=training)\n",
        "        return output, hidden\n",
        "\n",
        "    def initialize_hidden_state(self):\n",
        "        return tf.zeros((self.batch_size, self.enc_hidden_dim))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "SVI4MNFWK_G7",
        "colab": {}
      },
      "source": [
        "class Attention(tf.keras.layers.Layer):\n",
        "    \"\"\" bahdanau-style assistive attention \"\"\"\n",
        "\n",
        "    def __init__(self, units):\n",
        "        super(Attention, self).__init__()\n",
        "        self.d1 = tf.keras.layers.Dense(units)\n",
        "        self.d2 = tf.keras.layers.Dense(units)\n",
        "        self.d3 = tf.keras.layers.Dense(1)\n",
        "\n",
        "    def call(self, query, values):\n",
        "        \"\"\"\n",
        "        encoder last hidden state is the query\n",
        "        encoder outputs are the values\n",
        "        \"\"\"\n",
        "        # dim from (64,1024) -> (64,1,1024)\n",
        "        query_3d = tf.expand_dims(query, 1)\n",
        "\n",
        "        scores = self.d3(tf.nn.tanh(\n",
        "            self.d1(query_3d) + self.d2(values)))\n",
        "        # values.shape == (64, 17, 1024)\n",
        "\n",
        "        # tfa.seq2seq.LuongAttention\n",
        "        # tfa.seq2seq.BahdanauAttention\n",
        "\n",
        "        # axis 1 is the time axis, i.e. across multiple time steps\n",
        "        attention_weights = tf.nn.softmax(scores, axis=1)\n",
        "\n",
        "        context_vector = attention_weights * values\n",
        "        context_vector = tf.reduce_sum(context_vector, axis=1)\n",
        "\n",
        "        return context_vector, attention_weights"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "_TXDSwxE_HMT",
        "colab": {}
      },
      "source": [
        "class Decoder(tf.keras.Model):\n",
        "    def __init__(self, input_dim, embedding_dim, dec_hid_dim, dropout_rate=0.1):\n",
        "        super(Decoder, self).__init__()\n",
        "        self.dec_hid_dim = dec_hid_dim\n",
        "        self.embedding = tf.keras.layers.Embedding(input_dim, embedding_dim)\n",
        "        self.gru = tf.keras.layers.GRU(self.dec_hid_dim,\n",
        "                                    return_sequences=True,\n",
        "                                    return_state=True)\n",
        "        self.attention = Attention(self.dec_hid_dim)\n",
        "        self.dense = tf.keras.layers.Dense(input_dim)\n",
        "        self.dropout = tf.keras.layers.Dropout(dropout_rate)\n",
        "        \n",
        "    def call(self, x, query, value, training=True):\n",
        "        x = self.embedding(x)\n",
        "        x = self.dropout(x)\n",
        "        context_vector, attention_weights = self.attention(query, value)\n",
        "\n",
        "        # add one dimension to the context_vector, 2d->3d\n",
        "        # original dimension is (64, 17); dimension now is (64,17,1)\n",
        "        x = tf.concat([tf.expand_dims(context_vector, 1), x], axis=-1)\n",
        "        output, hidden = self.gru(x, training=training)\n",
        "        # tf.keras.layers.Bidirectional()\n",
        "\n",
        "        # output shape == (batch_size * 1, hidden_size)\n",
        "        output = tf.reshape(output, (-1, output.shape[2]))\n",
        "        x = self.dense(output)\n",
        "\n",
        "        return x, hidden, attention_weights"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "CVV4C2ElDLoJ"
      },
      "source": [
        "### Instantiate the models with sample batches"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "fGHE9L80TBUM",
        "colab": {}
      },
      "source": [
        "encoder = Encoder(english_vocab_size, EMBEDDING_DIM, ENC_HIDDEN_DIM, BATCH_SIZE)\n",
        "sample_hidden = encoder.initialize_hidden_state()\n",
        "example_input_batch, example_target_batch = next(iter(dataset))\n",
        "sample_output, sample_hidden = encoder(example_input_batch, sample_hidden)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "rh96LPYoys-i",
        "outputId": "b19da510-09cb-45ad-e0d1-df96e4e2707d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "print ('Encoder output shape: (batch size, sequence length, units) {}'.format(sample_output.shape))\n",
        "print ('Encoder Hidden state shape: (batch size, units) {}'.format(sample_hidden.shape))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Encoder output shape: (batch size, sequence length, units) (64, 17, 1024)\n",
            "Encoder Hidden state shape: (batch size, units) (64, 1024)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ha97KhRrNJzh",
        "outputId": "6c7d3059-5f94-4f55-cfeb-7edc29c6c021",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        }
      },
      "source": [
        "encoder.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"encoder\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        multiple                  798336    \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            multiple                  0         \n",
            "_________________________________________________________________\n",
            "gru (GRU)                    multiple                  3545088   \n",
            "=================================================================\n",
            "Total params: 4,343,424\n",
            "Trainable params: 4,343,424\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "EVsE_fjlTlNl",
        "outputId": "210b02a6-9d10-42d0-be83-e2cac795b105",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "attention_layer = Attention(1024)\n",
        "context_vector, attention_weights = attention_layer(sample_hidden, sample_output)\n",
        "\n",
        "print(\"Context vector shape: (batch size, units) {}\".format(context_vector.shape))\n",
        "print(\"Attention weights shape: (batch_size, sequence_length, 1) {}\".format(attention_weights.shape))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Context vector shape: (batch size, units) (64, 1024)\n",
            "Attention weights shape: (batch_size, sequence_length, 1) (64, 17, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Kw7LV9OuNa5x",
        "outputId": "ed57ee21-f144-4abb-f945-628620280918",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "attention_layer.count_params()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2100225"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "7uoGSFUCbhM2",
        "outputId": "4eebd030-1433-4762-f34b-a19f4b04667f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "decoder = Decoder(chinese_vocab_size, EMBEDDING_DIM, DEC_HIDDEN_DIM)\n",
        "\n",
        "sample_decoder_output, _, _ = decoder(tf.random.uniform((BATCH_SIZE, 1)),\n",
        "                                      sample_hidden, sample_output)\n",
        "\n",
        "print('Decoder output shape: (batch_size, vocab size) {}'.format(sample_decoder_output.shape))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Decoder output shape: (batch_size, vocab size) (64, 14052)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "KsAioxLJNMmT",
        "outputId": "124a12d9-1eb4-48f6-d2fc-3cdaa2e33664",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        }
      },
      "source": [
        "decoder.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"decoder\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_1 (Embedding)      multiple                  1798656   \n",
            "_________________________________________________________________\n",
            "gru_1 (GRU)                  multiple                  6690816   \n",
            "_________________________________________________________________\n",
            "attention_1 (Attention)      multiple                  2100225   \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              multiple                  14403300  \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          multiple                  0         \n",
            "=================================================================\n",
            "Total params: 24,992,997\n",
            "Trainable params: 24,992,997\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "aB-YTXPuDQJi"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Ngb95ug8Df2h"
      },
      "source": [
        "### Optimizer and loss Function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "s716hn1A-Pow",
        "colab": {}
      },
      "source": [
        "optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
        "cce = tf.keras.losses.SparseCategoricalCrossentropy(\n",
        "    from_logits=True, reduction='none')\n",
        "\n",
        "def loss_function(y_true, y_pred):\n",
        "    # returns True if y_true is not equal to 0 element-wise\n",
        "    # returns a vector\n",
        "    mask = tf.math.logical_not(tf.math.equal(y_true, 0))\n",
        "    loss_ = cce(y_true, y_pred)\n",
        "\n",
        "    mask = tf.cast(mask, dtype=loss_.dtype)\n",
        "    loss_ *= mask\n",
        "\n",
        "    return tf.reduce_mean(loss_)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ygVLUzIZDh6S"
      },
      "source": [
        "### Backpropagation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "GhAqprfQFSX2",
        "colab": {}
      },
      "source": [
        "# use @tf.function decorator to take advance of static graph computation\n",
        "@tf.function\n",
        "def train_step(inp, targ):\n",
        "    \n",
        "    teacher_forcing_ratio = 0.8\n",
        "    loss = 0   # initialize loss = 0\n",
        "\n",
        "    with tf.GradientTape() as tape:\n",
        "        # using the instantiated encoder object from before\n",
        "        # initialize hidden state with zeros on every epoch\n",
        "        enc_hidden = encoder.initialize_hidden_state()\n",
        "        enc_output, enc_hidden = encoder(inp, enc_hidden)\n",
        "        dec_hidden = enc_hidden\n",
        "        # dec_input.shape == (BATCH_SIZE, 1)\n",
        "        # initialize dec_input with the index of <start>\n",
        "        dec_input = tf.expand_dims([chinese_tokenizer.word_index['<start>']] * BATCH_SIZE, 1)\n",
        "        random_number = np.random.rand()\n",
        "        if random_number <= teacher_forcing_ratio:\n",
        "            use_teacher_forcing = True  \n",
        "        else:\n",
        "            use_teacher_forcing = False\n",
        "\n",
        "        # teacher-forcing: Feed the target as the next input\n",
        "        if use_teacher_forcing:\n",
        "            for t in range(1, targ.shape[1]):\n",
        "                pred, dec_hidden, att_weights = decoder(dec_input, dec_hidden, enc_output)\n",
        "                loss += loss_function(targ[:, t], pred)\n",
        "                # use the actual value the next input\n",
        "                dec_input = tf.expand_dims(targ[:, t], 1)\n",
        "        \n",
        "        # Without teacher forcing: use its own predictions as the next input\n",
        "        else:\n",
        "            for t in range(targ.shape[1]):\n",
        "                pred, dec_hidden, att_weights = decoder(dec_input, dec_hidden, enc_output)\n",
        "                # create (value, index) pair\n",
        "                topv, _ = tf.math.top_k(pred)\n",
        "                dec_input = topv\n",
        "                loss += loss_function(targ[:, t], pred)\n",
        "\n",
        "    batch_loss = (loss / int(targ.shape[1]))\n",
        "    variables = encoder.trainable_variables + decoder.trainable_variables\n",
        "    gradients = tape.gradient(loss, variables)\n",
        "    optimizer.apply_gradients(zip(gradients, variables))\n",
        "\n",
        "    return batch_loss"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "7tjybTebDkYI"
      },
      "source": [
        "### Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "XbIjEybuYqhg",
        "outputId": "3b0954c2-415d-4138-d6d8-f4803c6c1569",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "EPOCHS = 35\n",
        "loss_history = []\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "    # record training time\n",
        "    start = time.time()\n",
        "    # # initialize hidden state with zeros on every epoch\n",
        "    # enc_hidden = encoder.initialize_hidden_state()\n",
        "    \n",
        "    total_loss = 0\n",
        "\n",
        "    for batch, (inp, targ) in enumerate(dataset.take(STEPS_PER_EPOCH)):\n",
        "        batch_loss = train_step(inp, targ)\n",
        "        total_loss += batch_loss\n",
        "\n",
        "        if (batch+1) % 5 == 0:\n",
        "            print('=', end='')\n",
        "    \n",
        "    loss_history.append(total_loss/STEPS_PER_EPOCH)\n",
        "    print('\\nEpoch {} finished with Loss of {:.3f}'.format(epoch + 1, total_loss / STEPS_PER_EPOCH))\n",
        "    print('Time taken for 1 epoch {:.2f} seconds\\n'.format(time.time() - start))\n",
        "\n",
        "    # early stopping\n",
        "    if loss_history[epoch-1] - loss_history[epoch] < 0.01 and epoch != 0:\n",
        "        break"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "==============================================================\n",
            "Epoch 1 finished with Loss of 2.864\n",
            "Time taken for 1 epoch 72.23 seconds\n",
            "\n",
            "==============================================================\n",
            "Epoch 2 finished with Loss of 2.456\n",
            "Time taken for 1 epoch 56.56 seconds\n",
            "\n",
            "==============================================================\n",
            "Epoch 3 finished with Loss of 2.237\n",
            "Time taken for 1 epoch 56.52 seconds\n",
            "\n",
            "==============================================================\n",
            "Epoch 4 finished with Loss of 2.065\n",
            "Time taken for 1 epoch 56.65 seconds\n",
            "\n",
            "==============================================================\n",
            "Epoch 5 finished with Loss of 1.909\n",
            "Time taken for 1 epoch 56.76 seconds\n",
            "\n",
            "==============================================================\n",
            "Epoch 6 finished with Loss of 1.751\n",
            "Time taken for 1 epoch 56.76 seconds\n",
            "\n",
            "==============================================================\n",
            "Epoch 7 finished with Loss of 1.587\n",
            "Time taken for 1 epoch 56.56 seconds\n",
            "\n",
            "==============================================================\n",
            "Epoch 8 finished with Loss of 1.419\n",
            "Time taken for 1 epoch 56.70 seconds\n",
            "\n",
            "==============================================================\n",
            "Epoch 9 finished with Loss of 1.243\n",
            "Time taken for 1 epoch 56.66 seconds\n",
            "\n",
            "==============================================================\n",
            "Epoch 10 finished with Loss of 1.067\n",
            "Time taken for 1 epoch 56.67 seconds\n",
            "\n",
            "==============================================================\n",
            "Epoch 11 finished with Loss of 0.898\n",
            "Time taken for 1 epoch 56.67 seconds\n",
            "\n",
            "==============================================================\n",
            "Epoch 12 finished with Loss of 0.745\n",
            "Time taken for 1 epoch 56.67 seconds\n",
            "\n",
            "==============================================================\n",
            "Epoch 13 finished with Loss of 0.610\n",
            "Time taken for 1 epoch 56.72 seconds\n",
            "\n",
            "==============================================================\n",
            "Epoch 14 finished with Loss of 0.491\n",
            "Time taken for 1 epoch 56.67 seconds\n",
            "\n",
            "==============================================================\n",
            "Epoch 15 finished with Loss of 0.390\n",
            "Time taken for 1 epoch 56.61 seconds\n",
            "\n",
            "==============================================================\n",
            "Epoch 16 finished with Loss of 0.303\n",
            "Time taken for 1 epoch 56.53 seconds\n",
            "\n",
            "==============================================================\n",
            "Epoch 17 finished with Loss of 0.234\n",
            "Time taken for 1 epoch 56.53 seconds\n",
            "\n",
            "==============================================================\n",
            "Epoch 18 finished with Loss of 0.177\n",
            "Time taken for 1 epoch 56.49 seconds\n",
            "\n",
            "==============================================================\n",
            "Epoch 19 finished with Loss of 0.134\n",
            "Time taken for 1 epoch 56.59 seconds\n",
            "\n",
            "==============================================================\n",
            "Epoch 20 finished with Loss of 0.102\n",
            "Time taken for 1 epoch 56.58 seconds\n",
            "\n",
            "==============================================================\n",
            "Epoch 21 finished with Loss of 0.084\n",
            "Time taken for 1 epoch 56.62 seconds\n",
            "\n",
            "==============================================================\n",
            "Epoch 22 finished with Loss of 0.069\n",
            "Time taken for 1 epoch 56.73 seconds\n",
            "\n",
            "==============================================================\n",
            "Epoch 23 finished with Loss of 0.055\n",
            "Time taken for 1 epoch 56.65 seconds\n",
            "\n",
            "==============================================================\n",
            "Epoch 24 finished with Loss of 0.047\n",
            "Time taken for 1 epoch 56.59 seconds\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "BJ2pFLQs4LNj",
        "outputId": "f5b94124-706c-4251-9a9d-bf5aa50f7d44",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 499
        }
      },
      "source": [
        "# plot loss across epochs\n",
        "plt.figure(figsize=(12,8))\n",
        "plt.plot([(i+1) for i in range(len(loss_history))], loss_history)\n",
        "plt.xticks([(i+1) for i in range(len(loss_history))])\n",
        "plt.ylabel('Loss')\n",
        "plt.title('Loss across Epochs')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 864x576 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Bhy4bXZUDrX7"
      },
      "source": [
        "## Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Xke9Mr-NebxW",
        "colab": {}
      },
      "source": [
        "def get_eval_tensor(sentence):\n",
        "    processed_sentence = preprocess_sentence(sentence)\n",
        "    try:\n",
        "        inputs = [english_tokenizer.word_index[i] for i in processed_sentence.split(' ')]\n",
        "        inputs = pad_sequences([inputs], maxlen=english_tensor.shape[1], padding='post')\n",
        "        inputs = tf.convert_to_tensor(inputs)\n",
        "        return inputs\n",
        "    except:\n",
        "        return [0 for _ in processed_sentence.split(' ')]\n",
        "        # print('The Neural Network has not learned the word yet!')\n",
        "    \n",
        "def evaluate(sentence):\n",
        "    result = ''\n",
        "    # initialize encoder hidden layer\n",
        "    hidden = [tf.zeros((1, DEC_HIDDEN_DIM))]\n",
        "    enc_out, enc_hidden = encoder(get_eval_tensor(sentence), hidden, False)\n",
        "    # False means not using dropout\n",
        "    dec_hidden = enc_hidden\n",
        "    dec_input = tf.expand_dims([chinese_tokenizer.word_index['<start>']], 0)\n",
        "\n",
        "    attention_plot = np.zeros((chinese_tensor.shape[1], english_tensor.shape[1]))\n",
        "    \n",
        "\n",
        "    for t in range(english_tensor.shape[1]):\n",
        "        predictions, dec_hidden, attention_weights = decoder(\n",
        "            dec_input, dec_hidden, enc_out, False) \n",
        "        # False means not using dropout \n",
        "\n",
        "        predicted_id = tf.argmax(predictions[0]).numpy()\n",
        "        attention_weights = tf.reshape(attention_weights, (-1,))\n",
        "        attention_plot[t] = attention_weights.numpy()\n",
        "\n",
        "        try:\n",
        "            new_word = chinese_tokenizer.index_word[predicted_id] \n",
        "        except:\n",
        "            pass\n",
        "       \n",
        "        result += new_word + ' '\n",
        "        if chinese_tokenizer.index_word[predicted_id] == '<end>':\n",
        "            return result, attention_plot\n",
        "\n",
        "        dec_input = tf.expand_dims([predicted_id], 0)\n",
        "\n",
        "    return result, attention_plot"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "SA-Gv3RQnlUp",
        "colab": {}
      },
      "source": [
        "def plot_attention(attention, sentence, predicted_sentence):\n",
        "    fig = go.Figure(data = go.Heatmap(z=attention[:-1,:],\n",
        "                                      x=sentence,\n",
        "                                      y=[i for i in predicted_sentence[:-1][::-1]]))\n",
        "    fig.update_xaxes(side=\"top\")\n",
        "    fig.update_layout(\n",
        "        autosize=False,\n",
        "        width=700,\n",
        "        height=500,\n",
        "        margin=dict(l=50, r=50, b=5, t=2, pad=4)\n",
        "        )\n",
        "    fig.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "APjtko_wQ2R7"
      },
      "source": [
        "### Translate"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "d78weGGShrsv",
        "colab": {}
      },
      "source": [
        "def translate(sentence, plot=False, score=False):\n",
        "    result, attention_plot = evaluate(sentence)\n",
        "    if score == False:\n",
        "        print(result.replace(' ', '').strip('<end>'))\n",
        "    if score:\n",
        "        return result.strip('<end> ')\n",
        "    if plot:\n",
        "        attention_plot = attention_plot[:len(result.split(' ')), :len(sentence.split(' '))]\n",
        "        plot_attention(attention_plot, sentence.split(' '), result.split(' '))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "HrJ4gwd-AKEM",
        "outputId": "c2dbee9d-0c1e-4dc2-f360-ed423b0f6bc1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 534
        }
      },
      "source": [
        "translate('I am very hungry', plot = True)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "我很餓。\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>\n",
              "            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>\n",
              "                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script src=\"https://cdn.plot.ly/plotly-latest.min.js\"></script>    \n",
              "            <div id=\"7b742110-4533-4bb1-95f4-88a545f86565\" class=\"plotly-graph-div\" style=\"height:500px; width:700px;\"></div>\n",
              "            <script type=\"text/javascript\">\n",
              "                \n",
              "                    window.PLOTLYENV=window.PLOTLYENV || {};\n",
              "                    \n",
              "                if (document.getElementById(\"7b742110-4533-4bb1-95f4-88a545f86565\")) {\n",
              "                    Plotly.newPlot(\n",
              "                        '7b742110-4533-4bb1-95f4-88a545f86565',\n",
              "                        [{\"type\": \"heatmap\", \"x\": [\"I\", \"am\", \"very\", \"hungry\"], \"y\": [\"<end>\", \"\\u3002\", \"\\u9913\", \"\\u5f88\", \"\\u6211\"], \"z\": [[0.014076833613216877, 0.26605671644210815, 0.2668958604335785, 0.03902866318821907], [2.21686641452834e-05, 0.0001525978441350162, 0.003376050852239132, 0.05914563313126564], [0.12459857761859894, 0.0010658567771315575, 0.0016894276486709714, 0.004243629518896341], [0.442823201417923, 0.0026211219374090433, 0.004276738967746496, 0.005458591040223837], [0.6111838817596436, 0.009128632955253124, 0.005582579877227545, 0.011358015239238739]]}],\n",
              "                        {\"autosize\": false, \"height\": 500, \"margin\": {\"b\": 5, \"l\": 50, \"pad\": 4, \"r\": 50, \"t\": 2}, \"template\": {\"data\": {\"bar\": [{\"error_x\": {\"color\": \"#2a3f5f\"}, \"error_y\": {\"color\": \"#2a3f5f\"}, \"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"bar\"}], \"barpolar\": [{\"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"barpolar\"}], \"carpet\": [{\"aaxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"baxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"type\": \"carpet\"}], \"choropleth\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"choropleth\"}], \"contour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"contour\"}], \"contourcarpet\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"contourcarpet\"}], \"heatmap\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmap\"}], \"heatmapgl\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmapgl\"}], \"histogram\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"histogram\"}], \"histogram2d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2d\"}], \"histogram2dcontour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2dcontour\"}], \"mesh3d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"mesh3d\"}], \"parcoords\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"parcoords\"}], \"pie\": [{\"automargin\": true, \"type\": \"pie\"}], \"scatter\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter\"}], \"scatter3d\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter3d\"}], \"scattercarpet\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattercarpet\"}], \"scattergeo\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergeo\"}], \"scattergl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergl\"}], \"scattermapbox\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattermapbox\"}], \"scatterpolar\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolar\"}], \"scatterpolargl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolargl\"}], \"scatterternary\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterternary\"}], \"surface\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"surface\"}], \"table\": [{\"cells\": {\"fill\": {\"color\": \"#EBF0F8\"}, \"line\": {\"color\": \"white\"}}, \"header\": {\"fill\": {\"color\": \"#C8D4E3\"}, \"line\": {\"color\": \"white\"}}, \"type\": \"table\"}]}, \"layout\": {\"annotationdefaults\": {\"arrowcolor\": \"#2a3f5f\", \"arrowhead\": 0, \"arrowwidth\": 1}, \"coloraxis\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"colorscale\": {\"diverging\": [[0, \"#8e0152\"], [0.1, \"#c51b7d\"], [0.2, \"#de77ae\"], [0.3, \"#f1b6da\"], [0.4, \"#fde0ef\"], [0.5, \"#f7f7f7\"], [0.6, \"#e6f5d0\"], [0.7, \"#b8e186\"], [0.8, \"#7fbc41\"], [0.9, \"#4d9221\"], [1, \"#276419\"]], \"sequential\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"sequentialminus\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]]}, \"colorway\": [\"#636efa\", \"#EF553B\", \"#00cc96\", \"#ab63fa\", \"#FFA15A\", \"#19d3f3\", \"#FF6692\", \"#B6E880\", \"#FF97FF\", \"#FECB52\"], \"font\": {\"color\": \"#2a3f5f\"}, \"geo\": {\"bgcolor\": \"white\", \"lakecolor\": \"white\", \"landcolor\": \"#E5ECF6\", \"showlakes\": true, \"showland\": true, \"subunitcolor\": \"white\"}, \"hoverlabel\": {\"align\": \"left\"}, \"hovermode\": \"closest\", \"mapbox\": {\"style\": \"light\"}, \"paper_bgcolor\": \"white\", \"plot_bgcolor\": \"#E5ECF6\", \"polar\": {\"angularaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"radialaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"scene\": {\"xaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"yaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"zaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}}, \"shapedefaults\": {\"line\": {\"color\": \"#2a3f5f\"}}, \"ternary\": {\"aaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"baxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"caxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"title\": {\"x\": 0.05}, \"xaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}, \"yaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}}}, \"width\": 700, \"xaxis\": {\"side\": \"top\"}},\n",
              "                        {\"responsive\": true}\n",
              "                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('7b742110-4533-4bb1-95f4-88a545f86565');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })\n",
              "                };\n",
              "                \n",
              "            </script>\n",
              "        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "dNDhxZGHPDeS",
        "outputId": "752a3365-8b8e-4e44-c1ad-560f189ad4df",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 534
        }
      },
      "source": [
        "translate('He is the only person I know', plot = True)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "他是我认识的人。\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>\n",
              "            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>\n",
              "                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script src=\"https://cdn.plot.ly/plotly-latest.min.js\"></script>    \n",
              "            <div id=\"c7cba816-7329-4624-9428-e44a39cbf97b\" class=\"plotly-graph-div\" style=\"height:500px; width:700px;\"></div>\n",
              "            <script type=\"text/javascript\">\n",
              "                \n",
              "                    window.PLOTLYENV=window.PLOTLYENV || {};\n",
              "                    \n",
              "                if (document.getElementById(\"c7cba816-7329-4624-9428-e44a39cbf97b\")) {\n",
              "                    Plotly.newPlot(\n",
              "                        'c7cba816-7329-4624-9428-e44a39cbf97b',\n",
              "                        [{\"type\": \"heatmap\", \"x\": [\"He\", \"is\", \"the\", \"only\", \"person\", \"I\", \"know\"], \"y\": [\"<end>\", \"\\u3002\", \"\\u4eba\", \"\\u7684\", \"\\u8ba4\\u8bc6\", \"\\u6211\", \"\\u662f\", \"\\u4ed6\"], \"z\": [[0.00155766645912081, 0.339986652135849, 0.08326361328363419, 0.07209869474172592, 0.009527510963380337, 0.007164676673710346, 0.020582830533385277], [0.0003332244523335248, 0.00020222498278599232, 0.0037429898511618376, 0.06755342334508896, 0.2004740685224533, 0.07015169411897659, 0.15378224849700928], [0.05261871591210365, 0.0010871442500501871, 0.001186693785712123, 0.015489227138459682, 0.04364146292209625, 0.04941413924098015, 0.05200640484690666], [0.26273488998413086, 0.03786643594503403, 0.004663215018808842, 0.016576938331127167, 0.045028891414403915, 0.045252423733472824, 0.04471813887357712], [0.37879642844200134, 0.0033114065881818533, 0.0005857540527358651, 0.005640871822834015, 0.021901968866586685, 0.031927574425935745, 0.03193465620279312], [0.4386237859725952, 0.017145657911896706, 0.006409467197954655, 0.012521322816610336, 0.021334422752261162, 0.03038533218204975, 0.026323024183511734], [0.4568581283092499, 0.11334709823131561, 0.004259823821485043, 0.012342900037765503, 0.018854808062314987, 0.020125973969697952, 0.023526405915617943], [0.5237261652946472, 0.051267411559820175, 0.00656302971765399, 0.01337274257093668, 0.01671419106423855, 0.0205581896007061, 0.017577040940523148]]}],\n",
              "                        {\"autosize\": false, \"height\": 500, \"margin\": {\"b\": 5, \"l\": 50, \"pad\": 4, \"r\": 50, \"t\": 2}, \"template\": {\"data\": {\"bar\": [{\"error_x\": {\"color\": \"#2a3f5f\"}, \"error_y\": {\"color\": \"#2a3f5f\"}, \"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"bar\"}], \"barpolar\": [{\"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"barpolar\"}], \"carpet\": [{\"aaxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"baxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"type\": \"carpet\"}], \"choropleth\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"choropleth\"}], \"contour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"contour\"}], \"contourcarpet\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"contourcarpet\"}], \"heatmap\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmap\"}], \"heatmapgl\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmapgl\"}], \"histogram\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"histogram\"}], \"histogram2d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2d\"}], \"histogram2dcontour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2dcontour\"}], \"mesh3d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"mesh3d\"}], \"parcoords\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"parcoords\"}], \"pie\": [{\"automargin\": true, \"type\": \"pie\"}], \"scatter\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter\"}], \"scatter3d\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter3d\"}], \"scattercarpet\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattercarpet\"}], \"scattergeo\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergeo\"}], \"scattergl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergl\"}], \"scattermapbox\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattermapbox\"}], \"scatterpolar\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolar\"}], \"scatterpolargl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolargl\"}], \"scatterternary\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterternary\"}], \"surface\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"surface\"}], \"table\": [{\"cells\": {\"fill\": {\"color\": \"#EBF0F8\"}, \"line\": {\"color\": \"white\"}}, \"header\": {\"fill\": {\"color\": \"#C8D4E3\"}, \"line\": {\"color\": \"white\"}}, \"type\": \"table\"}]}, \"layout\": {\"annotationdefaults\": {\"arrowcolor\": \"#2a3f5f\", \"arrowhead\": 0, \"arrowwidth\": 1}, \"coloraxis\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"colorscale\": {\"diverging\": [[0, \"#8e0152\"], [0.1, \"#c51b7d\"], [0.2, \"#de77ae\"], [0.3, \"#f1b6da\"], [0.4, \"#fde0ef\"], [0.5, \"#f7f7f7\"], [0.6, \"#e6f5d0\"], [0.7, \"#b8e186\"], [0.8, \"#7fbc41\"], [0.9, \"#4d9221\"], [1, \"#276419\"]], \"sequential\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"sequentialminus\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]]}, \"colorway\": [\"#636efa\", \"#EF553B\", \"#00cc96\", \"#ab63fa\", \"#FFA15A\", \"#19d3f3\", \"#FF6692\", \"#B6E880\", \"#FF97FF\", \"#FECB52\"], \"font\": {\"color\": \"#2a3f5f\"}, \"geo\": {\"bgcolor\": \"white\", \"lakecolor\": \"white\", \"landcolor\": \"#E5ECF6\", \"showlakes\": true, \"showland\": true, \"subunitcolor\": \"white\"}, \"hoverlabel\": {\"align\": \"left\"}, \"hovermode\": \"closest\", \"mapbox\": {\"style\": \"light\"}, \"paper_bgcolor\": \"white\", \"plot_bgcolor\": \"#E5ECF6\", \"polar\": {\"angularaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"radialaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"scene\": {\"xaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"yaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"zaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}}, \"shapedefaults\": {\"line\": {\"color\": \"#2a3f5f\"}}, \"ternary\": {\"aaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"baxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"caxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"title\": {\"x\": 0.05}, \"xaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}, \"yaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}}}, \"width\": 700, \"xaxis\": {\"side\": \"top\"}},\n",
              "                        {\"responsive\": true}\n",
              "                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('c7cba816-7329-4624-9428-e44a39cbf97b');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })\n",
              "                };\n",
              "                \n",
              "            </script>\n",
              "        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "NFQr9yY1cmeN",
        "outputId": "e98e927e-b5ea-491d-d746-900af1240e1d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 534
        }
      },
      "source": [
        "translate('We move so fast that he cannot catch us', plot = True)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "我们的天气得他能赶上他。\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>\n",
              "            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>\n",
              "                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script src=\"https://cdn.plot.ly/plotly-latest.min.js\"></script>    \n",
              "            <div id=\"05611a10-ec84-4ca3-9195-aa6dbd80fa17\" class=\"plotly-graph-div\" style=\"height:500px; width:700px;\"></div>\n",
              "            <script type=\"text/javascript\">\n",
              "                \n",
              "                    window.PLOTLYENV=window.PLOTLYENV || {};\n",
              "                    \n",
              "                if (document.getElementById(\"05611a10-ec84-4ca3-9195-aa6dbd80fa17\")) {\n",
              "                    Plotly.newPlot(\n",
              "                        '05611a10-ec84-4ca3-9195-aa6dbd80fa17',\n",
              "                        [{\"type\": \"heatmap\", \"x\": [\"We\", \"move\", \"so\", \"fast\", \"that\", \"he\", \"cannot\", \"catch\", \"us\"], \"y\": [\"<end>\", \"\\u3002\", \"\\u4ed6\", \"\\u8d76\\u4e0a\", \"\\u80fd\", \"\\u4ed6\", \"\\u5f97\", \"\\u5929\\u6c14\", \"\\u7684\", \"\\u6211\\u4eec\"], \"z\": [[0.00026054258341901004, 0.16151052713394165, 0.06817492097616196, 0.03851042315363884, 0.027024123817682266, 0.04072745516896248, 0.02506406046450138, 0.11983908712863922, 0.051271479576826096], [0.0002971297944895923, 0.0002629606460686773, 0.03478895127773285, 0.1284714788198471, 0.10137539356946945, 0.11490777879953384, 0.06408590823411942, 0.2143958956003189, 0.039207395166158676], [0.07666736096143723, 0.0014005705015733838, 0.0048078433610498905, 0.030586181208491325, 0.05308132618665695, 0.06055714935064316, 0.06961429864168167, 0.05965558812022209, 0.08841919153928757], [0.04645630344748497, 0.03354395180940628, 0.005098833702504635, 0.01009772252291441, 0.03730437904596329, 0.04245813563466072, 0.08609700202941895, 0.0896231159567833, 0.0796804130077362], [0.26905694603919983, 0.004140716511756182, 0.0028010879177600145, 0.008056346327066422, 0.036302048712968826, 0.04735120013356209, 0.0538664311170578, 0.05316365137696266, 0.0671619325876236], [0.32807472348213196, 0.03452996537089348, 0.008384602144360542, 0.01649731583893299, 0.028522739186882973, 0.037519995123147964, 0.04983074218034744, 0.04594087228178978, 0.05952100455760956], [0.4159010350704193, 0.005173513665795326, 0.003872313303872943, 0.007801178842782974, 0.032877832651138306, 0.025344770401716232, 0.030547598376870155, 0.026159675791859627, 0.053810421377420425], [0.48325973749160767, 0.00685257650911808, 0.006192467175424099, 0.010339749045670033, 0.018101029098033905, 0.018147248774766922, 0.0342511385679245, 0.025080937892198563, 0.04508792981505394], [0.5784392356872559, 0.01418345607817173, 0.00565996952354908, 0.007962118834257126, 0.02531573921442032, 0.02803691290318966, 0.02846122905611992, 0.028230194002389908, 0.03143318369984627], [0.48026615381240845, 0.05859969183802605, 0.01663028635084629, 0.02981971949338913, 0.03608663007616997, 0.028877053409814835, 0.02512107975780964, 0.025183483958244324, 0.03613930568099022]]}],\n",
              "                        {\"autosize\": false, \"height\": 500, \"margin\": {\"b\": 5, \"l\": 50, \"pad\": 4, \"r\": 50, \"t\": 2}, \"template\": {\"data\": {\"bar\": [{\"error_x\": {\"color\": \"#2a3f5f\"}, \"error_y\": {\"color\": \"#2a3f5f\"}, \"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"bar\"}], \"barpolar\": [{\"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"barpolar\"}], \"carpet\": [{\"aaxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"baxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"type\": \"carpet\"}], \"choropleth\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"choropleth\"}], \"contour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"contour\"}], \"contourcarpet\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"contourcarpet\"}], \"heatmap\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmap\"}], \"heatmapgl\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmapgl\"}], \"histogram\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"histogram\"}], \"histogram2d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2d\"}], \"histogram2dcontour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2dcontour\"}], \"mesh3d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"mesh3d\"}], \"parcoords\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"parcoords\"}], \"pie\": [{\"automargin\": true, \"type\": \"pie\"}], \"scatter\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter\"}], \"scatter3d\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter3d\"}], \"scattercarpet\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattercarpet\"}], \"scattergeo\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergeo\"}], \"scattergl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergl\"}], \"scattermapbox\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattermapbox\"}], \"scatterpolar\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolar\"}], \"scatterpolargl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolargl\"}], \"scatterternary\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterternary\"}], \"surface\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"surface\"}], \"table\": [{\"cells\": {\"fill\": {\"color\": \"#EBF0F8\"}, \"line\": {\"color\": \"white\"}}, \"header\": {\"fill\": {\"color\": \"#C8D4E3\"}, \"line\": {\"color\": \"white\"}}, \"type\": \"table\"}]}, \"layout\": {\"annotationdefaults\": {\"arrowcolor\": \"#2a3f5f\", \"arrowhead\": 0, \"arrowwidth\": 1}, \"coloraxis\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"colorscale\": {\"diverging\": [[0, \"#8e0152\"], [0.1, \"#c51b7d\"], [0.2, \"#de77ae\"], [0.3, \"#f1b6da\"], [0.4, \"#fde0ef\"], [0.5, \"#f7f7f7\"], [0.6, \"#e6f5d0\"], [0.7, \"#b8e186\"], [0.8, \"#7fbc41\"], [0.9, \"#4d9221\"], [1, \"#276419\"]], \"sequential\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"sequentialminus\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]]}, \"colorway\": [\"#636efa\", \"#EF553B\", \"#00cc96\", \"#ab63fa\", \"#FFA15A\", \"#19d3f3\", \"#FF6692\", \"#B6E880\", \"#FF97FF\", \"#FECB52\"], \"font\": {\"color\": \"#2a3f5f\"}, \"geo\": {\"bgcolor\": \"white\", \"lakecolor\": \"white\", \"landcolor\": \"#E5ECF6\", \"showlakes\": true, \"showland\": true, \"subunitcolor\": \"white\"}, \"hoverlabel\": {\"align\": \"left\"}, \"hovermode\": \"closest\", \"mapbox\": {\"style\": \"light\"}, \"paper_bgcolor\": \"white\", \"plot_bgcolor\": \"#E5ECF6\", \"polar\": {\"angularaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"radialaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"scene\": {\"xaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"yaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"zaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}}, \"shapedefaults\": {\"line\": {\"color\": \"#2a3f5f\"}}, \"ternary\": {\"aaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"baxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"caxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"title\": {\"x\": 0.05}, \"xaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}, \"yaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}}}, \"width\": 700, \"xaxis\": {\"side\": \"top\"}},\n",
              "                        {\"responsive\": true}\n",
              "                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('05611a10-ec84-4ca3-9195-aa6dbd80fa17');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })\n",
              "                };\n",
              "                \n",
              "            </script>\n",
              "        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "BcIj400TN3IU",
        "outputId": "4bfbc3c4-c5ba-423e-fee6-24f946655db4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        }
      },
      "source": [
        "## Calculate BLEU Scores\n",
        "\n",
        "from nltk.translate.bleu_score import sentence_bleu\n",
        "from nltk.translate.bleu_score import SmoothingFunction\n",
        "\n",
        "test_dataset = tf.data.Dataset.from_tensor_slices((english_test, chinese_test)).shuffle(BUFFER_SIZE)\n",
        "\n",
        "def convert(lang, tensor):\n",
        "    words = []\n",
        "    for t in tensor.numpy():\n",
        "        if t!=0 and lang.index_word[t] not in ['<start>', '<end>']:\n",
        "            words.append(lang.index_word[t])\n",
        "    return words\n",
        "\n",
        "scores = []\n",
        "for eng, ref_trans in test_dataset:\n",
        "    reference = [convert(chinese_tokenizer, ref_trans)]\n",
        "    try:\n",
        "        eng = ' '.join(convert(english_tokenizer, eng))\n",
        "        eng = eng.replace('.', '')\n",
        "        candidate = translate(eng, score=True)\n",
        "        candidate = [i for i in candidate.split(' ')]\n",
        "    except:\n",
        "        pass\n",
        "\n",
        "    score = sentence_bleu(reference, candidate)\n",
        "    scores.append(score)\n",
        "\n",
        "print(np.mean(scores))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/nltk/translate/bleu_score.py:490: UserWarning:\n",
            "\n",
            "\n",
            "Corpus/Sentence contains 0 counts of 2-gram overlaps.\n",
            "BLEU scores might be undesirable; use SmoothingFunction().\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/nltk/translate/bleu_score.py:490: UserWarning:\n",
            "\n",
            "\n",
            "Corpus/Sentence contains 0 counts of 3-gram overlaps.\n",
            "BLEU scores might be undesirable; use SmoothingFunction().\n",
            "\n",
            "/usr/local/lib/python3.6/dist-packages/nltk/translate/bleu_score.py:490: UserWarning:\n",
            "\n",
            "\n",
            "Corpus/Sentence contains 0 counts of 4-gram overlaps.\n",
            "BLEU scores might be undesirable; use SmoothingFunction().\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "0.5230281683250283\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DXF5i50FnU16",
        "colab_type": "text"
      },
      "source": [
        "Reference\n",
        "\n",
        "https://www.tensorflow.org/tutorials/text/nmt_with_attention"
      ]
    }
  ]
}